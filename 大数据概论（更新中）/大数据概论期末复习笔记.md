# 1.绪论

## 1.概述

数据: 是所有能输入到计算机并被计算机程序处 是所有能输入到计算机并被计算机程序处理的符号的总称

数据的分类
– 结构化、半结构化、非结构化

## 2.大数据的内涵和外延

大数据4V特征：Volume，Velocity，Variety，Value

## 3.技术挑战和科学意义

### 1.数据的一般处理过程

• **数据获取** ：数据获取后，需要对数据进行变换、清洗等预处理，输出满足数据应用要求的数据
• **数据管理** ：对数据进行分类、编码、存储、索引和查询
• **数据分析** ：描述性分析、诊断性分析、预测性分析和规范性分析
• **数据可视化与交互分析** ：帮助业务人员而非数据处理专家更好的理解数据分析的结果

## 4.数据科学

# 2.大数据基本概念

## 1.大数据的概念

大数据是指以多元形式，自许多来源搜集而来的庞大数据组，往往具有实时性。在企业对企业销售的情况下，这些数据可能得自社交网络、电子商务网站、顾客来访纪录，还有许多其他来源。这些数据，并非公司顾客关系管理数据库的常态数据组。

## 2.大数据的来源

<img src="D:\Typora_CACHE\image-20220524162319439.png" alt="image-20220524162319439" style="zoom:50%;" />

• **结构化数据**简单来说就是数据库，如企业 简单来说就是数据库，如企业 ERP、 、 财务系统、医疗 系统、医疗 HIS数据库、教育一卡通、政府行政审 数据库、教育一卡通、政府行政审批、其他核心数据库等数据。
• **非结构化数据** 包括所有格式的办公文档、文本、图片、 片、 XML 、 HTML、 、 各类报表、图像和音频、视频信息等数据。

## 3.大数据的特征及意义

• 大数据的 3S
– 大数据是数据分析的前沿技术。从各种各样类型的数据中，快速高效获得有价值信息的能力，就是大数据技术。在 是大数据技术。在 IT 业界有的学者使用 3S来描述 来描述大数据，还有的学者使用 大数据，还有的学者使用 3I来描述大数据。 来描述大数据。
-Size：数据的大小
-Speed：数据的处理速度
-Structure：数据的结构化

大数据的 4V特征

<img src="D:\Typora_CACHE\image-20220524192853441.png" alt="image-20220524192853441" style="zoom:50%;" />

## 4.大数据的表现形态

• 大数据的表现形态
大数据在当今社会非常时髦，大数据的信息量是海量的，这个海量并不是某个时间端点的量级总结，而是持续更新，持续增量。由于大数据产生的过程中诸多的不确定性，使得大数据的表现形态多种多样。
– **多源性** ：大数据来源的复杂性。网络技术的迅猛发展使得数据产生的途径多样化。大数据结构的复杂性。非结构化数据的格式多样化，而这些非结构化数据中可能蕴藏着非常有价值的信息。
– **实时性** ：大数据的实时性，体现在数据更新的实时性。如何及时、有效、全面的捕获到互联网、物联网、云计算上产生的大量的不同来源的数据是会直接影响数据价值体现的关键因素。
– **不确定性** ：体现的是数据的不确定性。原始数据的不准确以及数据采集处理粒度、应用需求与数据集成和展示等因素使得数据在不同尺度、不同维度上都有不同程度的不确定性。

## 5.大数据的应用场景

<img src="D:\Typora_CACHE\image-20220524192932511.png" alt="image-20220524192932511" style="zoom:50%;" />

# 3.大数据感知与获取

**结构化信息**：这种信息可以在关系数据库中找到，多年来一直主导着 IT 应用，是关键任务 OLTP( 联机事务处理) ) 系统业务所依赖的信息。另外，这种信息还可对结构数据库信息进行排序和查询。例如VF 中的表。
**半结构化信息**：包括电子邮件、文字处理文件及大量保存和发布在网络上的信息。
**非结构化信息**：该信息在本质形式上可认为主要是位映射数据。

## 1.大数据获取

### 1.行业/企业内数据

不同用户和企业内部不同部门提供的内部数据可能来自不同的途径，其数据内容、数据格式和数据质量千差万别，因此 ，**能否对数据进行有效的整合将成为是否能够对内部数据进行有效利用和关键，ETL 是其中重要的处理手段**

#### 1.ETL-抽取

数据抽取是从数据源中抽取数据的过程，由于数据会存放在数据库里，数据抽取也就变成了从数据库中抽取数据的过程。由于大多数场景下，数据会存放在数据库里，从数据库中抽取数据一般分为两种方式：
1 ）**全量抽取**
全量抽取就是对整个数据库的所有数据进行抽取，将数据源库中的所有数据原封不动的从数据库中抽取出来，然后转换成ETL工具可以识别的格式。
2 ）**增量抽取**
增量抽取只抽取自上次抽取以来数据库中新增或修改的数据。优秀的捕获方法应该做到能够将数据库中的变化数据以较高的准确率获得的同时不对业务系统造成太大的压力而影响现有业务。

#### 2.ETL-转化和加工

从数据源中抽取的数据不一定满足目的数据库的要求，需要对抽取出的数据进行数据转换和加工，主要有两种操作方式。
1 ） **ETL 引擎中的数据转换和加工**：ETL引擎中一般以组件化的方式实现数据转换，常用的数据转换组件有字段映射、数据过滤、数据替换、数据计算、数据验证、数据加解密、数据合并、数据拆分等。
2 ）**在数据库中进行数据加工**：关系数据库本身已经提供强大的SQL指令、函数来支持数据的加工，如在SQL查询语句中添加where条件进行过滤、查询中重复名字段名与目的表进行映射等。

**常用规则如下**：
1 ）字段级的转换。主要是指数据类型转换，增加“上下文”数据，例如时间戳；将数值型的地域编码替换成地域名称，如解码(decoding)等。
2 ）清洁和净化。主要是保留字段具有特定值或特定范围的记录；引用完整性检查；去除重复记录等。
3 ）多数据源整合。字段映射(mapping)、代码变换(transposing)、合并(merging) 、派生(derivation)。
4 ）聚合 (aggregation) 和汇总 (summarization)。事务性数据库侧重于细节，数据仓库侧重于高层次的聚合和汇总。

#### 3.数据清洗

数据清洗是指在数据集中发现不准确、不完整或不合理数据，并对这些数据进行修补或移除以提高数据质量的过程，主要步骤包括：
1）定义错误类型
2）搜索并标识错误实例
3）改正错误
4）文档记录错误实例和错误类型
5）修改数据录入程序以减少未来的错误。

#### 4.ETL-加载

将转换和加工后的数据加载到目的库中通常是ETL最后步骤，加载数据的最佳方式取决于所执行操作的类型以及需要装入多少数据，当目的库时关系数据库时，一般有两种装载方式：
1）直接中SQL语句进行插入、更新、删除操作。
2）采用批量装载方式，如bp、bulk、关系数据库特有的批量装载工具或者API.

#### 5.ETL常用工具

<img src="D:\Typora_CACHE\image-20220524193916355.png" alt="image-20220524193916355" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220524193928652.png" alt="image-20220524193928652" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220524193945036.png" alt="image-20220524193945036" style="zoom:67%;" />

### 2.互联网数据

#### 1.互联网数据特性

1 ）多源异构性
2 ）交互性
3 ）时效性
4 ）社会性
5 ）突发性
6 ）高噪音

#### 2.网络爬虫

在网络爬虫的系统框架中，主过程由控制器，解析器，资源库三部分组成。
**控制器**：控制器的主要工作是负责给多线程中的各个爬虫线程分配工作任务。
**解析器**：解析器的主要工作是下载网页，进行页面的处理，主要是将一些JS脚本标签、CSS代码内容、空格字符、HTML标签等内容处理掉，爬虫的基本工作是由解析器完成。
**资源库**：资源库是用来存放下载到的网页资源，一般都采用大型的数据库存储，如Oracle数据库，并对其建立索引。

<img src="D:\Typora_CACHE\image-20220524194330877.png" alt="image-20220524194330877" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220524194342695.png" alt="image-20220524194342695" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220524194351951.png" alt="image-20220524194351951" style="zoom:67%;" />

1 ）**批量型爬虫， BatchCrawler**
批量型爬虫有较明确的抓取范围及抓取目标，目标可能是一段时间，也可能是一批网页，一旦完成要求的抓取要求，则爬虫就会停止抓取进程，算是完成了此阶段批量的抓取任务。
2 ）**增量型爬虫， IncrementalCrawler**
不同于批量型爬虫，增量型爬虫会持续不断地抓取网页，并且要对新抓到的网页进行更新。又称“通用爬虫”，在搜索业务内，如百度、Google采用的都是增量型爬虫。
3 ）**垂直型爬虫， FocusCrawler**
垂直型爬虫关注在某一个固定的专题内容或者固定的行业网页。在互联网行业，存在千万种行业分类，垂直型爬虫要明确爬虫哪方面的内容，进而对此行业内进行抓取。一般垂直型搜索引擎，如携程，就会重点抓取出行方面的数据，不会考虑到食品类别的网页。

**网络爬虫 URL 抓取策略有：**
	IP 地址搜索策略
	广度优先
	深度优先
	最佳优先
	反向链接数策略
	Partial PageRank策略
	OPIC策略策略

### 3.物联网数据

**三大特征**：
**全面感知**：利用RFID、传感器、二维码等能够随时随地采集物体的动态信息。
**可靠传送**：通过各种有线和无线网络与互联网融合，将物体的信息实时准确地传递出去。
**智能处理**：物联网不仅仅提供了传感器的连接，其本身也具有智能处理的能力，能够对物体实施智能控制。

#### 1.物联网大数据获取——RFID

RFID（射频识别，俗称电子标签）技术是一种无接触的自动识别技术，利用射频信号及其空间耦合传输特性，实现对静态或移动待识别物体的自动识别，用于对采集点的信息进行“标准化”标识，。鉴于RFID技术可实现无接触的自动识别，全天候工作、识别穿透能力强、无接触磨损，可同时实现对多个物品的自动识别等诸多特点，将这一技术应用到物联网领域，使其与互联网、通信技术相结合，可实现全球范围内物品的跟踪与信息的共享，在物联网“识别”信息和近程通讯的层面中，起着至关重要的作用。

#### 2.物联网大数据获取——传感器

传感器可以采集大量信息，它是许多装备和信息系统必备的信息摄取器件。若无传感器对最初信息的检测、交替和捕获，所有控制与测试都不能实现。即使是最先进的计算机，若是没有信息和可靠数据，都不能有效地发挥传感器本身的作用。传感器技术的突破和发展有3个方面：网络化、感知信息、智能化。

# 4.数据管理

## 1.数据管理概述

• 数据管理技术
– **数据管理技术是指对数据进行分类、编码、存储、索引和查询，是大数据处理流程中的关键技术，负责数据从落地存储（写）到查询检索（读）的核心系统。** 数据管理技术从最早人们使用文件管理数据，到数据库、数据仓库技术的出现与成熟，再到大数据时代NoSQL等新型数据管理系统的涌现，一直是数据领域研究和工程领 等新型数据管理系统的涌现，一直是数据领域研究和工程领域的热点。
• 数据库
– **数据库 数据库 (Database)是按照数据结构来组织、存储和管理数据的建立 是按照数据结构来组织、存储和管理数据的建立在计算机存储设备上的仓库。** 简单来说是本身可视为电子化的文件
柜，用户可以对文件中的数据进行新增、截取、更新、删除等操作。严格来说，数据库是长期储存在计算机内、有组织的、可共享的数据集合。

## 2.关系数据库

关系数据库建立在关系数据模型之上，是主要用来存储结构化数据并支持数据的插入、查询、更新、删除等操作的数据库。

• **关系数据模型** 是以集合论中的关系概念为基础发展起来的。 **关系数据模型中无论是实体还是实体间的联系均由单一的数据结构 ——关系来表示**。 关系数据模型中对的数据操作通常由关系代数和关系演算两种抽象操作语言来完成，此外关系数据模型中还通过实体完整性、参照完整性和自定义完整性来确保数据的完整一致
• 关系数据模型的基本数据结构就是关系（Relation）， **一个关系对应着一个二维表，二维表的名字就是关系名**

## 3.分布式文件系统

分布式文件系统建立在通过网络联系在一起的多台价格相对低廉的服务器上，将要存储
的文件按照特定的策略划分成多个片段分散放置在系统中的多台服务器上。

• 从用途来看，目前主流的分布式文件系统主要有
两类：
– 第一类分布式文件系统主要 **面向以大文件、块数据顺序读写为特点的数据分析业务，其典型代表是 读写为特点的数据分析业务，其典型代表是 Apache旗下 旗下的 HDFS**。
– 另一类主要服务于通用文件系统需求并支持标准的 **可移植操作系统接口**（ Portable Operating System Interface ofUNIX ，缩写为 POSIX ），其代表包括 Ceph 和 GlusterFS。

• 这种分类仅表示各种分布式文件系统的专注点有所不同，并非指一种分布式文件系统只能用于某种用途。

### 1.Hadoop 分布式文件系统（ HDFS）： 

**特点**：
HDFS 作为 Hadoop 的分布式文件系统 ， 其功能为数据的存储 、 管理和出错处理 。 它是类似于 GFS 的开源版本 ， 设计的目的是用于可靠地存储大规模的数据集 ， 并提高用户访问数据的效率 。

<img src="D:\Typora_CACHE\image-20220524200334544.png" alt="image-20220524200334544" style="zoom:67%;" />

**架构和操作**：
HDFS 采用的是单一主服务器的主从结构，一个 HDFS集群通常由一台主 集群通常由一台主服务器和若干台数据服务器构成，有一台后备主服务器用于定期对主服务器存储的元数据进行备份，保障名称空间、元数据等系统信息的完整性。这台后备主服务器只与主服务器进行交互，对系统中的其他节点不可见。

<img src="D:\Typora_CACHE\image-20220524200436563.png" alt="image-20220524200436563" style="zoom:67%;" />

**副本管理**：
为了提高系统中文件数据的可靠性， 为了提高系统中文件数据的可靠性， HDFS系统提供了一种副本机制： 默认情况下，每一个文件块都会在 HDFS系统中拥有三个副本，副本数 系统中拥有三个副本，副本数可以在部署集群时手动设置。通常这三个副本会被放置在不同的数据服务器上，这样就保证了即便其中某一个副本丢失或者损坏，都可以保证该文件块可以继续使用，甚至还可以利用其他两个副本来恢复丢失或者损坏的那个副本。

<img src="D:\Typora_CACHE\image-20220524200533097.png" alt="image-20220524200533097" style="zoom:67%;" />

### 2.Ceph

• Ceph是一个高可用、易于管理、开源的分布式存 是一个高可用、易于管理、开源的分布式存储系统，可以同时提供对象存储、块存储以及文件存储服务，其优势包括统一存储能力、可扩展性、可靠性、性能、自动化的维护等等。
• Ceph优势均来源于其先进的核心设计思想，可其概 优势均来源于其先进的核心设计思想，可其概括为八个字 括为八个字 ——**“无需查表，算算就好”**。基于这种设计思想， 种设计思想， Ceph充分发挥存储设备自身的计算能 充分发挥存储设备自身的计算能力，同时消除了对系统单一中心节点的依赖，从而实现了真正的 **无中心结构** 。
• Ceph 项目起源于其创始人 Sage Weil在加州大学圣克 在加州大学圣克鲁兹分校攻读博士期间的研究课题。

<img src="D:\Typora_CACHE\image-20220524200639914.png" alt="image-20220524200639914" style="zoom:67%;" />

• 相对于面向离线批处理的 相对于面向离线批处理的 HDFS 来说， Ceph更偏向于成为一种高性能、高可靠、高扩展性的实时分布式存储系统，其对于写入操作特别是随机写入的支持要更好。

### 3.GlusterFs

• GlusterFS 是 Scale- - Out 存储解决方案 Gluster的核心，它是一个开源的分布式文件系统，具有强大的横向扩展能力，通过扩展能够支持数 PB存储容量和处存储容量和处理数千客户端。

• GlusterFS 借助 TCP/IP 或 InfiniBand RDMA网络将物 网络将物理分布的存储资源聚集在一起，使用单一全局命名空间来管理数据。 空间来管理数据。 GlusterFS基于可堆叠的用户空间 基于可堆叠的用户空间设计，可为各种不同的数据负载提供优异的性能。

<img src="D:\Typora_CACHE\image-20220524200800524.png" alt="image-20220524200800524" style="zoom:67%;" />

• GlusterFS 支持运行在任何标准 IP网络上标准应用程序的标 网络上标准应用程序的标准客户端，用户可以在全局统一的命名空间中使用NFS/CI等标准协议来访问应用数据。 等标准协议来访问应用数据。
• GlusterFS使得用户可摆脱原有的独立、高成本的封闭存储 使得用户可摆脱原有的独立、高成本的封闭存储系统，能够利用普通廉价的存储设备来部署可集中管理、横向扩展、虚拟化的存储池，存储容量可扩展至 横向扩展、虚拟化的存储池，存储容量可扩展至 TB/PB级。 级。
• GlusterFS由于缺乏一些关键特性，可靠性也未经过长时间 由于缺乏一些关键特性，可靠性也未经过长时间考验，还不适合应用于需要提供 考验，还不适合应用于需要提供 24 小时不间断服务的产品 小时不间断服务的产品环境。目前适合应用于大数据量的离线应用。

### 4.对比

<img src="D:\Typora_CACHE\image-20220524200842768.png" alt="image-20220524200842768" style="zoom:67%;" />

## 4.新型数据管理与查询系统

### 1.NoSQL数据库

**NoSQL （ Not only SQL）数据库**是对于非关系型的一类数据库系统的统称。它**针对关系型数据库在管理键值对、文档、图等类型数据上的不足，针对各个类型数据的存储和访问特点而专门设计的数据库管理系统。**

<img src="D:\Typora_CACHE\image-20220524201016289.png" alt="image-20220524201016289" style="zoom:67%;" />

### 2.SQL on Hadoop系统

互联网公司最先遇到大数据难题，需要为海量互联网网页构建倒排列表。 2004 年， Google 公司提出 MapReduce技术，作为面向大数据分析技术，作为面向大数据分析和处理的并行计算模型，引起了工业界和学术界的广泛关注。 和处理的并行计算模型，引起了工业界和学术界的广泛关注。Hadoop技术很快也影响了数据库研究领域，有面向简单的键值对读写事务型负载的 负载的 NoSQL 系统（如 HBase 等），也有面向数据分析任务的 Hive系统。

Hive 系统的出现，一改传统的 OLAP只能在关系数据仓库中运行的局面， 只能在关系数据仓库中运行的局面，从而可以对从而可以对 HDFS 中存储的结构化数据，基于一种类似 SQL 的 HiveQL语言，进行 言，进行 ROLAP方式的数据分析。

#### 1.Hive

自从 Facebook 在 2007 年推出 Apache Hive 系统及其 HiveQL 语言以来，已经成为 已经成为 Hadoop 平台标准的 SQL 实现。Hive把HiveQL查询首先转换 查询首先转换成MapReduce 作业，然后在 Hadoop集群上执行。某些操作（如连接 集群上执行。某些操作（如连接操作）被翻译成若干个操作）被翻译成若干个 MapReduce作业，依次执行。 

#### 2.Impala

– Impala 是由 Cloudera 公司推出的一个支持交互式（实时）查询的 SQL on Hadoop 系统。 Impala 放弃使用效率不高的 MapReduce计算模型， 计算模型，设计专有的查询处理框架，把执行计划分解以后，分配给相关节点运行，而不是把执行计划转换为一系列的运行，而不是把执行计划转换为一系列的 MapReduce作业。
– Impala 不把中间结果持久化到硬盘上，而是使用 MPP数据库惯用的 数据库惯用的技术，即基于内存的数据传输，在各个操作之间传输数据。 在连接操作的处理方面， 操作的处理方面， Impala根据表的绝对和相对大小，在不同的连接 根据表的绝对和相对大小，在不同的连接算法之间进行选择。

#### 3.Spark SQL

park SQL使用内存列存储技术支持分析型应用。 使用内存列存储技术支持分析型应用。 在复杂查询执行过程中，中间结果通过内存进行传输，无需持久化到硬盘上，极大地提高了查询的执行性能。

# 5.1数据理解与特征工程

## 1.数据类型

– 数据
• 狭义：数字 。
• 广义：数据对象及其属性的集合，其表现形式可以是数字、符号、文字、图像抑或是计算机代码等等。
– 属性
•  ( 也称为特征、维或字段) ，是指一个对象的某方 ，是指一个对象的某方面性质或特性。一个对象通过若干属性来刻画。
– 数据集
• 数据对象的集合 数据对象的集合( 同分布、同特征）

### 1.数据集的特征

• **维度(Dimensionality)**
– 指数据集中的对象具有的属性个数总和 。
– 维归约
• **稀疏性(Sparsity)**
– 指在某些数据集中，有意义的数据非常少，对象在大部分属性上的取值为 部分属性上的取值为0 0 ；非零项不到 1%。
– 文本数据集
• **分辨率(Resolution)**
– 不同分辨率下数据的性质不同

### 2.数据集的类别

– 记录数据
• 事务数据或购物篮数据
• 数据矩阵
• 文本数据

– 基于图形的数据
• 万维网
• 化合物结构

– 有序数据
• 时序数据
• 序列数据
• 时间序列数据
• 空间数据
• 流数据

## 2.数据规范

数据规范化：使不同规格的数据转换到同一规格

<img src="D:\Typora_CACHE\image-20220525142744904.png" alt="image-20220525142744904" style="zoom:67%;" />

**Z-Score标准化**

<img src="D:\Typora_CACHE\image-20220525142828246.png" alt="image-20220525142828246" style="zoom:67%;" />

## 3.度量方法

• 在机器学习和数据挖掘中，我们经常需要知道 **个体间差异的大小** ，进而评价 **个体的相似性和类别** 。根据数据特性的不同，可以采用不同的度量方法。
– 距离函数
– 度量函数

<img src="D:\Typora_CACHE\image-20220525142909189.png" alt="image-20220525142909189" style="zoom:67%;" />

#### 1.距离

##### 1.欧氏距离

<img src="D:\Typora_CACHE\image-20220525142945272.png" alt="image-20220525142945272" style="zoom:67%;" />

##### 2.曼哈顿距离

<img src="D:\Typora_CACHE\image-20220525143013762.png" alt="image-20220525143013762" style="zoom:67%;" />

##### 3.切比雪夫距离

<img src="D:\Typora_CACHE\image-20220525143035338.png" alt="image-20220525143035338" style="zoom:67%;" />

##### 4.马式距离

<img src="D:\Typora_CACHE\image-20220525143130228.png" alt="image-20220525143130228" style="zoom:67%;" />

#### 2.相似度度量

相似度度量（ Similarity），即计算个体间的相似程度，与距离度量相反， **相似度度量的值越小** ，说明个体间相 **似度越小 ， 差异越大**。
– 余弦相似度
– 皮尔森相关系数
– Jaccard 相似系数

##### 1.余弦相似度

<img src="D:\Typora_CACHE\image-20220525143321433.png" alt="image-20220525143321433" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525143342072.png" alt="image-20220525143342072" style="zoom:67%;" />

##### 2.皮尔森相关系数

<img src="D:\Typora_CACHE\image-20220525143350244.png" alt="image-20220525143350244" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525143405980.png" alt="image-20220525143405980" style="zoom:67%;" />

##### 3.Jaccard相似系数

<img src="D:\Typora_CACHE\image-20220525143418271.png" alt="image-20220525143418271" style="zoom:67%;" />

## 4.特征工程

<img src="D:\Typora_CACHE\image-20220525143430645.png" alt="image-20220525143430645" style="zoom:67%;" />

### 1.特征表示

 特征表示，是将数据转换为有利于后续分析和处理的形式而进行的一种形式化表示和描述。
– 不同类型数据使用不同特征表示方法
– 特征表示有利于后续的分析处理
– 模型输出为可计算向量，特征表示无歧义表示
– 借鉴专家知识，能够提高特征表示质量
– 对原始数据数字化后的特征表示可以描述原始对象

### 2.特征构造

#### 1.聚合特征构造

• 聚合特征构造主要通过对多个特征的分组聚合实现，这些特征通常来自同一张表或者多张表的联立。
• 聚合特征构造使用一对多的关联来对观测值分组，然后计算统计量。
• 常见的分组统计量有中位数、算术平均数、众数、最小值、最大值、标准差、方差和频数等 。

#### 2.转换特征构造

相对于聚合特征构造依赖于多个特征的分组统计，通常依赖于对于特征本身的变换。转换特征构造使用单一特征或多个特征进行变换后的结果作为新的特征。常见的转换方法有单调转换（幂变换、log变换、绝对值等）、线性组合、多项式组合、比例、排名编码和异或值等。

### 3.特征提取

提取对象：原始数据（特征提取一般是在特征选择之前）
提取目的：自动地构建新的特征，将原始数据转换为一组具有明显物理意义（比如几何特征、纹理特征）或者统计意义的特征。

<img src="D:\Typora_CACHE\image-20220525143640498.png" alt="image-20220525143640498" style="zoom:67%;" />

#### 1.降维

##### 1.PCA

<img src="D:\Typora_CACHE\image-20220525143740261.png" alt="image-20220525143740261" style="zoom:67%;" />

##### 2.ICA

<img src="D:\Typora_CACHE\image-20220525143754107.png" alt="image-20220525143754107" style="zoom:67%;" />

#### 2.图像

##### 1.SIFT特征

<img src="D:\Typora_CACHE\image-20220525143948130.png" alt="image-20220525143948130" style="zoom:67%;" />

##### 2.HOG特征

<img src="D:\Typora_CACHE\image-20220525144008671.png" alt="image-20220525144008671" style="zoom:67%;" />

#### 3.文本

##### 1.词袋模型

<img src="D:\Typora_CACHE\image-20220525144036173.png" alt="image-20220525144036173" style="zoom:67%;" />

##### 2.N-gram模型

<img src="D:\Typora_CACHE\image-20220525144050731.png" alt="image-20220525144050731" style="zoom:67%;" />

### 4.特征选择

<img src="D:\Typora_CACHE\image-20220525144108173.png" alt="image-20220525144108173" style="zoom:67%;" />

**特征选择的三种方法**：

筛选器(Filter):
先对数据集进行特征选择，其过程与后续学习器无关，即设计一些统计量来过滤特征，并不考虑后续学习器问题
封装器(Wrapper):
就是一个分类器，它是将后续的学习器的性能作为特征子集的评价标准
嵌入式(Embedding):
是学习器自主选择特征

# 5.2常用数据挖掘算法

## 1.机器学习

机器学习是数据通过算法构建出模型并对模型进行评估，评估的性能如果达到要求就拿这个模型来测试其他的数据，如果达不到要求就调整算法来重新建立模型，再次进行评估 ，循环往复 ，最终获得满意 的模型来 处理其他的数据

## 2.非监督学习-关联规则挖掘&聚类分析

### 1.关联规则挖掘基本概念

• 关联规则反映一个事物与其他事物之间的相互依存性和关联性。如果两个或者多个事物之间存在一定的关联关系，那么，其中一个事物就能够通过其他事物预测到。
• 典型的关联规则发现问题是对超市中的货篮数据（MarketBasket） 进行分析。通过发现顾客放入货篮中的不同商品之间的关系来分析顾客的购买习惯。
• 许多重要数据挖掘任务的基础
– 关联、相关性、因果性
– 序列模式、空间模式、时间模式、多维
– 关联分类、聚类分析

• 关联规则挖掘
– 首先被Agrawal, Imielinski and Swami 在1993 年的SIGMOD 会议上提出
– 在事务、关系数据库中的项集和对象中发现频繁模式、关联规则、相关性或者因果结构
– **频繁模式**: 数据库中频繁出现的项集

• 目的: 发现数据中的规律
– 超市数据中的什么产品会一起购买？— 啤酒和尿布
– 在买了一台PC 之后下一步会购买?
– 哪种DNA 对这种药物敏感?
– 我们如何自动对Web

• **关联规则**（ Association rule ）：指从事务数据库、关系数据库和其他信息存储中的大量数据的项集之间发现有趣的、频繁出现的模式、关联和相关性 。 关联 规则是 支持度和信任度分别满
足用户给定阈值的规则。

• **关联分析**（ Association analysis ）：用于发现隐藏在大型数据集中的令人感兴趣的联系。所发现的联系可以用关联规则或者频繁项集的形式表示。关联规则挖掘就是从大量的数据中挖掘
出描述数据项之间相互联系的有价值的有关知识。

#### 1 项（ Item ）、项集（ Itemset ）、k- 项集与事务

**项**：是指数据库中不可分割的最小单位。
**项集**：是指多个项的集合，其中，空集是指不包含任何项的项集。
**k-项集**：是指由k 个项构成的项集组合。
**事务**：是指用户定义的一个数据库操作序列，这些操作序列是一个不可分割的工作单位 。

#### 2 频繁项集（ Frequent Itemset ）

**频繁项集**：是指在所有训练元组中同时出现的次数，超过人工定义的阈值的项集。在关联规则的挖掘过程中，一般只保留候选项集中满足支持度条件的项集，不满足条件的舍弃。

#### 3 极大频繁项集（ Frequent Large Itemset ）

**极大频繁项集**：不存在包含当前频繁项集的频繁超集，则当前频繁项集就是极大频繁项集 。

#### 4 支持度（ Support ）

**支持度**：是指项集在所有训练元组中同时出现的次数，因此，支持度可以表述为 Support(X->Y) = |X U Y|/ |N| 。其中，X ，Y  N ，X∩Y=Ф ， |X U Y| 表示集合X与Y在一个事务中同时出现的次数， |N| 表示数据记录的总个数

#### 5 置信度（ Confidence ）

置信度可以表述为： Confidence (X->Y)= |X U Y|/ |X| =Support(X->Y) / Support （X），其中，X ，Y  N ， X∩Y= Ф ，| X U Y|表示集合X与Y在一个事务中同时出现的次数， |X|表示X出现的总次数。

### 2.关联规则的挖掘过程

<img src="D:\Typora_CACHE\image-20220525144933400.png" alt="image-20220525144933400" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525144945178.png" alt="image-20220525144945178" style="zoom:67%;" />

一般地，关联规则挖掘问题可以划分成两个子问题：
1 ）**发现频繁项目集**
通过用户给定的 Minsupport ，寻找所有频繁项目集，即满足 Support 不小于 Minsupport 的项目集。事实上，这些频繁项目集可能具有包含关系。一般地，我们只关心那些不被其它频繁项目集所包含的所谓频繁大项集的集合。这些频繁大项集是形成关联规则基础 。
2 ）**生成关联规则**
通过用户给定的 Minconfidence ，在每个最大频繁项目项目集中，寻找Confidence 不小于 Minconfidence

<img src="D:\Typora_CACHE\image-20220525145029554.png" alt="image-20220525145029554" style="zoom:67%;" />

**强关联规则**

<img src="D:\Typora_CACHE\image-20220525145054843.png" alt="image-20220525145054843" style="zoom:67%;" />

### 3.关联规则的Apriori算法

Apriori 算法基于频繁项集性质的先验知识，使用由下至上逐层搜索的迭代方法，即从频繁1项集开始，采用频繁k项集搜索频繁 k+1 项集，直到不能找到包含更多项的频繁项集为止。

• 性质1 频繁项集的子集必为频繁项集。
• 性质2 非频繁项集的超集一定是非频繁的。

Apriori 算法由以下步骤组成，其中的核心步骤是连接步和剪枝步 ：

#### 1 连接步 

为了找到频繁 为了找到频繁k项集Lk ，首先将 Lk-1与自身连接，产生候选k项集Ck ， Lk-1的元素是可连接的。

#### 2 剪枝步

候选k项集 Ck 是 Lk 的超集，因此， Ck 成员即可为频繁项集也可不是频繁的，但所有的频繁项集都包括在 Ck 中。扫描数据库，确定 Ck 中每一个候选的计数，从而确定 Lk （计数值不小于最小支持度计数的所有候选是频繁的，从而属于 Lk ）。然而， Ck 可能很大，这样所涉及的计算量就很大。为压缩 Ck ，使用 Apriori 性质：任何非频繁的 (k-1)项集都不可能是频繁k项集的子集。因此，如果一个候选k项集的 (k-1）项集不在 Lk 中，则该候选项也不可能是频繁的，从而可以由 Ck 中删除。这种子集测试可以使用所有频繁项集的散列树快速完成。

#### 3 步骤三

<img src="D:\Typora_CACHE\image-20220525145518056.png" alt="image-20220525145518056" style="zoom:67%;" />

实用教程：https://www.bilibili.com/video/BV1AJ411x7sf?share_source=copy_pc

### 4.聚类分析

• 聚类（Cluster ）算法的核心思想就是 将具有相似特征的事物给“聚”在一起，也就是说“聚”是一个动词。俗话说人以群分，物以类聚说得就是这个道理。

<img src="D:\Typora_CACHE\image-20220525155012543.png" alt="image-20220525155012543" style="zoom:67%;" />

### 5.k-means算法原理

• k-means 聚类算法也被称为k 均值聚类， 其算法的核心思想是通过迭代把数据对象划分到不同的簇中，以求目标函数最小化，从而使生成的簇尽可能地紧凑和独立。

算法主要步骤如下：
① 首先随机选择k 个样本点作为k 个簇的初始簇中心；
② 然后计算每个样本点与这个k 个簇中心的相似度大小 ， 并将该 样本点划分 到与之相似度最大的簇中心所对应的簇中；
③ 根据每个簇中现有的样本，重新计算每个簇的簇中心；
④ 循环迭代步骤 ②③，直到目标函数收敛，即簇中心不再发生变化

• 输入 期望得到的簇的数目k ，n 个对象的数据库。
• 输出 使得平方误差准则函数最小化的k个簇。
• 方法
	– 选择k个对象作为初始的簇的质心；
	– repeat
	– 计算对象与各个簇的质心的距离，将对象划分到距离其最近的簇；
	– 重新计算每个新簇的均值；
	– until簇的质心不再变化

### 6.k-means算法求解

<img src="D:\Typora_CACHE\image-20220525155304359.png" alt="image-20220525155304359" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525155335871.png" alt="image-20220525155335871" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525155349927.png" alt="image-20220525155349927" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220525155533029.png" alt="image-20220525155533029" style="zoom:67%;" />

### 7.聚类评估指标

• 一个好的聚类方法要能产生高质量的聚类结果——簇，这些簇要具备以下两个特点：
– **高的簇内相似性**
– **低的簇间相似性**
• 聚类结果的好坏取决于该聚类方法采用的相似性评估方法以及该方法的具体实现；
• 聚类方法的好坏还取决与该方法是能发现某些还是所有的隐含模式；

**纯度**

<img src="D:\Typora_CACHE\image-20220525155615979.png" alt="image-20220525155615979" style="zoom:67%;" />



## 3.监督学习-回归&分类

### 1.线性回归

#### 1.线性回归模型建立

<img src="D:\Typora_CACHE\image-20220601142836964.png" alt="image-20220601142836964" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601143502560.png" alt="image-20220601143502560" style="zoom:67%;" />

对于如何求解模型 对于如何求解模型𝒉(𝒙)的问题就转换成了如何最小化函 的问题就转换成了如何最小化函数 数𝑱(𝒘,𝒃)的问题 的问题 。而 而𝑱(𝒘,𝒃)也有一个专门的术语叫**目标函数 （Objective Function ） 或者是代价函数 （Cost Function ） 亦或是损失函数 。**

<img src="D:\Typora_CACHE\image-20220601143628425.png" alt="image-20220601143628425" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601143638883.png" alt="image-20220601143638883" style="zoom:67%;" />

#### 2.梯度下降算法求解

<img src="D:\Typora_CACHE\image-20220601143653639.png" alt="image-20220601143653639" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601144021891.png" alt="image-20220601144021891" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601150037850.png" alt="image-20220601150037850" style="zoom:67%;" />

#### 3.回归模型评估

**平均绝对误差MAE**：

<img src="D:\Typora_CACHE\image-20220601150115989.png" alt="image-20220601150115989" style="zoom:67%;" />

**均方误差MSE**：

<img src="D:\Typora_CACHE\image-20220601151225080.png" alt="image-20220601151225080" style="zoom:67%;" />

#### 4.回归模型非线性变化

<img src="D:\Typora_CACHE\image-20220601151239236.png" alt="image-20220601151239236" style="zoom:67%;" />

**多项式函数**：

<img src="D:\Typora_CACHE\image-20220601154553957.png" alt="image-20220601154553957" style="zoom:67%;" />

**高斯函数**：

<img src="D:\Typora_CACHE\image-20220601154610740.png" alt="image-20220601154610740" style="zoom:67%;" />

**Sigmod函数**：

<img src="D:\Typora_CACHE\image-20220601154630806.png" alt="image-20220601154630806" style="zoom:67%;" />

### 2.Logistic回归

Logistic回归一般用于 回归一般用于分类（ Classification）问题 ，而其本质是线性回归模型，只是在回归的连续值结果上加了一层函数映射。

#### 1.模型建立

<img src="D:\Typora_CACHE\image-20220601154755060.png" alt="image-20220601154755060" style="zoom:67%;" />

分类问题看0还是1

<img src="D:\Typora_CACHE\image-20220601154828204.png" alt="image-20220601154828204" style="zoom:67%;" />

#### 2.模型求解

<img src="D:\Typora_CACHE\image-20220601154845870.png" alt="image-20220601154845870" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601162143228.png" alt="image-20220601162143228" style="zoom:67%;" />

#### 3.模型评估

<img src="D:\Typora_CACHE\image-20220601162155138.png" alt="image-20220601162155138" style="zoom:67%;" />

### 3.KNN（最近邻算法）

K 最近邻 （K-nearest beighbor，KNN ） 分类算法 。 KNN 方法的出发点是：如果一个样本在特征空间中的k个最相似 （ 特征空间中最近邻 ） 的样本中的大多数属于某一个类别 ， 则该样本也属于这个类别 ， 并具有这个类别样本的特性 。

<img src="D:\Typora_CACHE\image-20220601162453021.png" alt="image-20220601162453021" style="zoom:67%;" />

对于 K 最近邻算法的原理可以总结为如下3 个步骤：
a) 首先确定一个 K 值 值 ； 用于选择离自己 （ 三角形样本点 ） 最近的样本数 。
b) 然后选择一种度量 距离 ；的 用来计算得到离自己最近的K 个样本 （ 例如最为广泛的欧氏距离 ） 。
c) 最后 确定一种 决策规则 ； 用来判定新样本所属类别 （ 例如示例中采用了基于投票的分类规则 ） 。

可以看出，KNN 分类的3 个步骤其实也就对应了3 个超参数的选择 。 但是 ， 通常来说对于决策规则的选择基本上都是采用了基于投票的分类规则 。

<img src="D:\Typora_CACHE\image-20220601162557488.png" alt="image-20220601162557488" style="zoom:67%;" />

### 4.朴素贝叶斯

朴素贝叶斯分类是利用统计学中的贝叶斯定理来预测类成员的概率 ， 既给定一个样本 ， 计算该样本属于一个特定的类的概率 ，朴素贝叶斯分类基于的一个假设是：每个属性之间都是相互独立的 ， 并且每个属性对分类问题产生的影响都是一样的 。

#### 1.朴素贝叶斯概念

 先验概率
先验概率是指根据历史经验得出来的概率 。
如某 在某 2 分类数据集中 ， 正样本有4个 ，有 负样本有 6 个 ， 那么通过这个数据集能够学习到的先验知识便是任取一个样本 ， 其为正样本的可能性为 40%， 负样本的可能性为 60% ， 而这就被称之为先验概率

 后验概率
所谓后验概率是指通过贝叶斯公式推断得到的结果 。
例如上述例子中 ， 不能因为负样本出现的可能性为 60%就判定任意取出的样本为负样本 。 先验知识只能先取得一个大致的判断 ， 而事实情况需要根据先验概率和条件概率来进行计算 。

极大后验概率估计
极大后验概率是指在所有后验概率中选择其中最大的一个 。
例如上述例子中，根据先验概率和条件概率便可以计算出每个样本属于正样本还是负样本的后验概率。最后在判断该样本属于何种类别时，挑选后验概率最大的类别即可。

极大似然估计
极大似然估计是指用来估计能使得当前已知结果最有可能发生的模型参数的过程 。例如某次抛硬币的结果为正面4次，反面6次。那么什么样的模型参数能够使得这一结果最可能发生呢？此时只需最大化下式即可：<img src="D:\Typora_CACHE\image-20220601162855418.png" alt="image-20220601162855418" style="zoom:33%;" />

其中𝑝为正面向上的概率。

#### 2.理解朴素贝叶斯

<img src="D:\Typora_CACHE\image-20220601162955514.png" alt="image-20220601162955514" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163018734.png" alt="image-20220601163018734" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163056970.png" alt="image-20220601163056970" style="zoom:67%;" />

#### 3.计算实例

<img src="D:\Typora_CACHE\image-20220601163145750.png" alt="image-20220601163145750" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163205355.png" alt="image-20220601163205355" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163228359.png" alt="image-20220601163228359" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163240522.png" alt="image-20220601163240522" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220601163249356.png" alt="image-20220601163249356" style="zoom:67%;" />

# 5.3深度学习简介

## 1.从人工神经网络到深度神经网络

人类大脑中的神经网络是由一个个神经元组成的，神经元由细胞体、轴突、、动作电位、突出末端、突触前神经元的轴突和树突等部分组成。身体的不同部位产生的信息通过不同的路径到达神经元，神经元处理它并产生一个输出。（神经元也可能被连接到另一个神经元。）

<img src="D:\Typora_CACHE\image-20220606142514742.png" alt="image-20220606142514742" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220606142533918.png" alt="image-20220606142533918" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220606142600784.png" alt="image-20220606142600784" style="zoom:67%;" />

## 2.卷积神经网络的若干改进

<img src="D:\Typora_CACHE\image-20220606142715344.png" alt="image-20220606142715344" style="zoom:67%;" />

### 1.输入层

<img src="D:\Typora_CACHE\image-20220606142810919.png" alt="image-20220606142810919" style="zoom:67%;" />

### 2.卷积层

<img src="D:\Typora_CACHE\image-20220606142826479.png" alt="image-20220606142826479" style="zoom:67%;" />

### 3.参数共享

<img src="D:\Typora_CACHE\image-20220606142853188.png" alt="image-20220606142853188" style="zoom:67%;" />

### 4.稀疏连接

<img src="D:\Typora_CACHE\image-20220606142904190.png" alt="image-20220606142904190" style="zoom:67%;" />

### 5.池化层

<img src="D:\Typora_CACHE\image-20220606142921694.png" alt="image-20220606142921694" style="zoom:67%;" />

### 6.全连接层

<img src="D:\Typora_CACHE\image-20220606142940298.png" alt="image-20220606142940298" style="zoom:67%;" />

### 7.输出层

<img src="D:\Typora_CACHE\image-20220606142953931.png" alt="image-20220606142953931" style="zoom:67%;" />

卷积网络的核心思想是将：局部感受野、权值共享以及降采样这三种结构思想结合起来获得了某种程度的位移、尺度、形变不变性，以达到 数据 降维的特征学习与分类。

• 全连接网络
	– 权重矩阵的参数 非常 多
• 卷积神经网络
	– 生物学上感受野
• 卷积 神经网络结构上的特性：
	– 稀疏连接
	– 权重共享

## 3.循环神经网络若干改进

### 1.RNN

循环神经网络（ 神经网络（ recurrent neural network, RNN）是一种人 ）是一种人工神经网络，除了层间的连接以外，同层个单元之间连接构成了一个有向图序列，这种结构允许显示一个时间序列的动态时间行为。

– 循环神经网络通过使用带自反馈的神经元，能够处理任意长度的序列。
– 循环神经网络比前馈神经网络更加符合生物神经网络的结构。
– 循环神经网络已经被广泛应用在语音识别、语言模型以及自然语言生成等任务上。

RNN 与传统神经网络的不同之处在于其允许对向量的序列进行操作，**输入输出都可以是序列**。由于一个序列当前的输出与前面的输出也有关， RNN 需要有记忆特性，具体表现为 RNN 会对前面的信息进行记忆并应用于当前输出的计算中，既隐藏层之间的节点不再是无连接的而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。

<img src="D:\Typora_CACHE\image-20220606144619787.png" alt="image-20220606144619787" style="zoom:67%;" />

### 2.LSTM

传统 RNN较难训练，往往会出现梯度消失或者梯度抱着等，为 较难训练，往往会出现梯度消失或者梯度抱着等，为了解决这一问题， 了解决这一问题， RNN出现了多个扩展版本，在此介绍一种重 出现了多个扩展版本，在此介绍一种重要模型——LSTM

<img src="D:\Typora_CACHE\image-20220606144720044.png" alt="image-20220606144720044" style="zoom:67%;" />

#### 1.忘记门

<img src="D:\Typora_CACHE\image-20220606144836671.png" alt="image-20220606144836671" style="zoom:67%;" />

#### 2.输入门

<img src="D:\Typora_CACHE\image-20220606144850156.png" alt="image-20220606144850156" style="zoom:67%;" />

#### 3.输出门

<img src="D:\Typora_CACHE\image-20220606144902966.png" alt="image-20220606144902966" style="zoom:67%;" />

#### 4.细胞更新

<img src="D:\Typora_CACHE\image-20220606144913418.png" alt="image-20220606144913418" style="zoom:67%;" />

<img src="D:\Typora_CACHE\image-20220606144923993.png" alt="image-20220606144923993" style="zoom:67%;" />

## 4.生成式对抗神经网络

生成对抗网络由一个生成网络与一个判别网络组成。生成网络从潜在空间（ latent space ）中随机采样作为输入，其输出结果需要尽量模仿训练集中的真实样本。
• 判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。

<img src="D:\Typora_CACHE\image-20220606145952364.png" alt="image-20220606145952364" style="zoom:67%;" />

GANs 有 两个网络, ,成 分别是生成 器G和判别器D。它们的功能分别是 :
• G作为一个生成图片的网络, , 它接收一个随机的噪声 z, 通过这个噪声生成图片,记做 G(z)
• D作为一个判别网络, , 判别一张图片是不是“真实的” 。 它的输入参数是 x,x 代表一张图片,输出 D(x) 代表x为真实图片的概率, 如果为 1,就代表 100% 是真实的图片, , 而输出为 0, 就代表不是真实图片 。
• 在训练过程中 ,G 的目标就是尽量生成真实的图片去 欺欺骗D而D的 目标就是尽量把G生成的图片和真实的图片区分开。这样G和D构成了一个动态的“博弈过程”。

其中,G 代表生成器。代表判别器,训练时分别对D和G进行交互迭代固定G, 优化 D, 一段时间后,固定D再优化 G,

(1)使用全卷积网络。在判别模型中, , 使用带步长的卷积 ( sidedconvolutions)取代空间池化 取代空间池化 ( spatial pooling)。这种形式可以让更多的前层信息传递到 。这种形式可以让更多的前层信息传递到后层上去。另外 后层上去。另外, , 在生成模型中, , 使用反卷积机制 (fractional strided),可以学 可以学
习自己的空间上采样。
(2) 取消了全连接层, ,直接用卷积层连接输入层和输出层 直接用卷积层连接输入层和输出层
(3) 批归一化 ( batch normalization)。除了生成器模型的输出层和判别器模 。除了生成器模型的输出层和判别器模型的输人层 型的输人层, , 在网络其他层上都使用了批归一化, , 使川批归化可以稳定学习, ,有助于处理初始化不良导致的训练问题。
(4) 在生成器的输出层采用 Tanh 做激励函数, , 其他层使用 ReLU做激励函数。 做激励函数。判别器上统一使用 判别器上统一使用 eaky Relu做激励函数 
