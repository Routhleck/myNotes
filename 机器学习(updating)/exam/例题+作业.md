# 概念

## 评估方法

数据集包含1000个样本，其中500个正例，500个反例、将其划分为包含70%样本的训练集和30%样本的测试集用于留出法评估，试估算共有多少种划分方式。

留出法要尽可能保持数据分布的一致性。
因此70%样本的训练集要有700个样本，分别为350个正例和350个反例; 30%的测试集要有300个样本，分别有150个正例和150个反例。

因此共有![img](例题+作业.assets/clip_image002.gif)或![img](例题+作业.assets/clip_image002-1672663938409-2.gif)种划分方式

# 线性模型

## 一元线性回归

为研究某化学反应过程中，温度x对产品得率y的影响，测得数据如下：

| 温度 | 100  | 110  | 120  | 130  | 140  | 150  | 160  | 170  | 180  | 190  |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 得率 | 45   | 51   | 54   | 61   | 66   | 70   | 74   | 78   | 85   | 89   |

根据上述实验数据，建立一元线性回归方程。当温度为200℃时，得率是多少

![image-20230102205305662](例题+作业.assets/image-20230102205305662.png)

先列出线性方程y=wx+b
然后构建J再进行求导

<img src="例题+作业.assets/image-20230102205501136.png" alt="image-20230102205501136" style="zoom: 50%;" />

# 感知机和神经网络

## 感知机正常求解

<img src="例题+作业.assets/image-20230102210119546.png" alt="image-20230102210119546" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210139098.png" alt="image-20230102210139098" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210153167.png" alt="image-20230102210153167" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210217578.png" alt="image-20230102210217578" style="zoom:40%;" />

## 感知机对偶形式

<img src="例题+作业.assets/image-20230102210312194.png" alt="image-20230102210312194" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210322097.png" alt="image-20230102210322097" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210334483.png" alt="image-20230102210334483" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102210733238.png" alt="image-20230102210733238" style="zoom: 80%;" />

![image-20230103234832862](例题+作业.assets/image-20230103234832862.png)

<img src="例题+作业.assets/image-20230103234854607.png" alt="image-20230103234854607"  />

<img src="例题+作业.assets/image-20230102210740832.png" alt="image-20230102210740832" style="zoom:80%;" />

## 感知机求解异或问题

Minsky与Papert指出：感知机因为是线性模型，所以不能表示复杂的函数，如异或（XOR）。（1）验证感知机为什么不能表示异或；（2）设计一个两层感知机用于解决异或问题。

<img src="例题+作业.assets/image-20230102210608232.png" alt="image-20230102210608232" style="zoom:130%;" />

<img src="例题+作业.assets/image-20230102210434557.png" alt="image-20230102210434557" style="zoom:40%;" />

# 支持向量机 

<img src="例题+作业.assets/image-20230102211134671.png" alt="image-20230102211134671" style="zoom: 40%;" />

1、已知正例点![img](例题+作业.assets/clip_image002-1672665187039-4.gif)，![img](例题+作业.assets/clip_image004.gif)，![img](例题+作业.assets/clip_image006.gif)，负例点![img](例题+作业.assets/clip_image008.gif)，![img](例题+作业.assets/clip_image010.gif) 

试求最大间隔分离超平面和分类决策函数,并在图上画出分离超平面、间隔边界及支持向量。

<img src="例题+作业.assets/image-20230102211313206.png" alt="image-20230102211313206" style="zoom: 80%;" /><img src="例题+作业.assets/image-20230103235220868.png" alt="image-20230103235220868"  /><img src="例题+作业.assets/image-20230102211322927.png" alt="image-20230102211322927" style="zoom: 67%;" />

# 贝叶斯分类

<img src="例题+作业.assets/image-20230102211539154.png" alt="image-20230102211539154" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211550159.png" alt="image-20230102211550159" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211559061.png" alt="image-20230102211559061" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211719444.png" alt="image-20230102211719444" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211728307.png" alt="image-20230102211728307" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211757237.png" alt="image-20230102211757237" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230102211816338.png" alt="image-20230102211816338" style="zoom:40%;" />

试由下表的训练数据学习一个朴素贝叶斯分类器并确定X=(age="<=30",income="M",student="Y",credit_rating="fair")该样本的buys_computer属性值是啥(Y/N)？

<img src="例题+作业.assets/image-20230102212001723.png" alt="image-20230102212001723" style="zoom: 80%;" />

<img src="例题+作业.assets/image-20230103235524404.png" alt="image-20230103235524404"  />![image-20230103235556702](例题+作业.assets/image-20230103235556702.png)![image-20230103235616409](例题+作业.assets/image-20230103235616409.png)



<img src="例题+作业.assets/image-20230102212014649.png" alt="image-20230102212014649" style="zoom:50%;" />

# 决策树

## ID3

<img src="例题+作业.assets/image-20230103134959883.png" alt="image-20230103134959883" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103135013216.png" alt="image-20230103135013216" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103135026199.png" alt="image-20230103135026199" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103135042316.png" alt="image-20230103135042316" style="zoom:40%;" />

## C4.5

<img src="例题+作业.assets/image-20230103135252683.png" alt="image-20230103135252683" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103141440541.png" alt="image-20230103141440541" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103141452374.png" alt="image-20230103141452374" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103141504810.png" alt="image-20230103141504810" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103141515063.png" alt="image-20230103141515063" style="zoom:40%;" />

根据表1中所给的训练数据集，利用信息增益比（C4.5算法）生成决策树。表1是一个由15个样本组成的贷款申请训练数据。数据包括贷款申请人的4个特征（属性）：第1个特征是年龄，有3个可能值：青年，中年，老年；第2个特征是有工作，有2个可能值：是，否；第3个特征是有自己的房子，有2个可能值：是，否；第4个特征是信贷情况，有3个可能值：非常好，好，一般。表的最后一列是类别，是否同意贷款，取2个值：是，否。

<img src="例题+作业.assets/image-20230103141719417.png" alt="image-20230103141719417" style="zoom:67%;" />![image-20230103235835611](例题+作业.assets/image-20230103235835611.png)![image-20230103235910607](例题+作业.assets/image-20230103235910607.png)![image-20230103235933682](例题+作业.assets/image-20230103235933682.png)![image-20230103235958402](例题+作业.assets/image-20230103235958402.png)![image-20230104000013915](例题+作业.assets/image-20230104000013915.png)![image-20230104000031706](例题+作业.assets/image-20230104000031706.png)![image-20230104000043843](例题+作业.assets/image-20230104000043843.png)

<img src="例题+作业.assets/image-20230103141728047.png" alt="image-20230103141728047" style="zoom:45%;" /><img src="例题+作业.assets/image-20230103141738275.png" alt="image-20230103141738275" style="zoom:45%;" />

<img src="例题+作业.assets/image-20230103141748224.png" alt="image-20230103141748224" style="zoom:50%;" />

# 集成学习

## 简述AdaBoost和GBDT之间的联系和区别。

联系:Adaboost 和 GBDT 都属于 boosting 提升方法，都是基于加法模型和前向分步算法。
区别: Adaboost 用错分数据点来识别问题，通过调整错分数据点的权重来改进模型。GBDT 通过负梯度来识别问题，通过计算负梯度来改进模型。

## 比较支持向量机、AdaBoost、逻辑斯谛回归模型的学习策略与算法。

**支持向量机**

> - **学习策略：**结构风险最小化;间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数最小化问顾
> - **学习算法：**求解凸二次规划的最优化算法、对偶算法、SMO算法等

**AdaBoost**

> - **学习策略：**经验 风险 最小化;极小化加法模型的指 数 损失，通过一系列弱分类器来构造一个强分类器
> - **学习算法：**加法模型和前向分步算法，提升树算法等

**逻辑斯谛回归**

> - **学习策略：**经验风险最小化;极大似然估计，正则化的极大似然估计。
> - **学习算法：**改进的迭代尺度算法，梯度下降，拟牛顿法等。

# 聚类

## 原型聚类Kmeans

<img src="例题+作业.assets/image-20230103151806309.png" alt="image-20230103151806309" style="zoom:67%;" />

<img src="例题+作业.assets/image-20230103151815187.png" alt="image-20230103151815187" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103151831531.png" alt="image-20230103151831531" style="zoom:40%;" />

试用k均值算法将下列样本聚到2个类中。

<img src="例题+作业.assets/image-20230103153134517.png" alt="image-20230103153134517" style="zoom:80%;" />

第一轮
先随机选择两个样本点作为聚类中心
以这两个点为聚类中心，计算各点到中心的欧氏距离平方，给每个点进行分类
接着得到新的类计算其中心

迭代重复计算分类，直至各类元素均与上一轮不一致，停止迭代。

<img src="例题+作业.assets/image-20230103153144118.png" alt="image-20230103153144118" style="zoom:50%;" />



## 密度聚类DBSCAN

<img src="例题+作业.assets/image-20230103152010816.png" alt="image-20230103152010816" style="zoom:50%;" />

<img src="例题+作业.assets/image-20230103152020547.png" alt="image-20230103152020547" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152209749.png" alt="image-20230103152209749" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152230907.png" alt="image-20230103152230907" style="zoom:40%;" />

## 层次聚类 

### 聚合聚类

<img src="例题+作业.assets/image-20230103152450300.png" alt="image-20230103152450300" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152501622.png" alt="image-20230103152501622" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152530824.png" alt="image-20230103152530824" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152539623.png" alt="image-20230103152539623" style="zoom:40%;" />

<img src="例题+作业.assets/image-20230103152548678.png" alt="image-20230103152548678" style="zoom:40%;" />

### 分裂聚类

<img src="例题+作业.assets/image-20230103152647269.png" alt="image-20230103152647269" style="zoom:40%;" />

**简要概括密度聚类和层次聚类的算法特性，并指出这两种聚类算法分别适用于什么场景。**

**密度聚类的算法特性：**没有使用距离作为度量，而是依据样本分布的紧密程度来确定聚类结构。其使用一定邻域内点的数量作为连通性的标准，并基于该连通性不断扩展聚类族得到最终的聚类结果。基于密度的聚类可以处理形状不规则的类，如 spherical 球状，drawn-out 拉长，linear 线状，elongated 细长等

**层次聚类的算法特性：**层次聚类(Hierarchical Clustering)是聚类算法的一种，通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。创建聚类树有自下而上合并和自上而下分裂两种方法。

密度聚类的适应场景：当数据的空间距离具有显著的集群特性时，例如500个单一类别的样本可用密度聚类技术将它们划分成多个不同的子类。此外，在高斯混合模型中，也非常适用于对数据进行划分。

层次聚类的适应场景：当数据之间存在一定的嵌套特性时，可以使用层次聚类。层次聚类不需要事先定义子集个数（可以放在停止条件），而是采用迭代方式来根据相似度来将样本逐步地分成更加详尽的子集。

# 降维

**简述k值的选择对k近邻法结果产生的影响？**
如果k值过小，则模型可能过于敏感，容易受到噪声的影响，导致模型的分类准确率降低。反之，如果k值过大，则模型可能过于平滑，容易把不同类别的样本混淆，导致模型的分类准确率也降低。
常用交叉验证在训练集上训练不同的k值，并在验证集上评估模型的性能，选择性能最优的k值作为最终的模型。另外，也可以使用网格搜索等方法来自动寻找最优的k值。

## KNN算法流程

<img src="例题+作业.assets/image-20230103155532513.png" alt="image-20230103155532513" style="zoom:40%;" />

**对以下样本数据进行主成分分析**

![image-20230103155610632](例题+作业.assets/image-20230103155610632.png)

用PCA的方法将这组二维数据降到一维。

![image-20230104001053952](例题+作业.assets/image-20230104001053952.png)

<img src="例题+作业.assets/image-20230103155630919.png" alt="image-20230103155630919" style="zoom:80%;" />